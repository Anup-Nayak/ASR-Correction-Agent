{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anup/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from queue import PriorityQueue\n",
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ans = pd.read_json('ans.json')\n",
    "my_ans = pd.read_json('ans1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.pkl', 'rb') as fp:\n",
    "        data = pickle.load(fp)\n",
    "with open('data/phoneme_table.json', 'r') as fp:\n",
    "        phenome_table = json.load(fp)\n",
    "with open('data/vocabulary.json', 'r') as fp:\n",
    "        vocabulary = json.load(fp)\n",
    "class CostModel(object):\n",
    "    def __init__(self) -> None:\n",
    "        # Load Whisper model and processor\n",
    "        self.__processor = WhisperProcessor.from_pretrained(\"openai/whisper-small.en\")\n",
    "        self.__model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small.en\").to(DEVICE)\n",
    "        self.__audio_inputs = None\n",
    "\n",
    "    def set_audio(self, audio, sampling_rate):\n",
    "        self.__audio_inputs = self.__processor(\n",
    "            audio, sampling_rate=sampling_rate, return_tensors=\"pt\"\n",
    "        ).input_features.to(DEVICE)\n",
    "\n",
    "    def get_loss(self, text):\n",
    "        # Prepare the target text input IDs\n",
    "        target = self.__processor(\n",
    "            text=text, return_tensors=\"pt\", padding=True\n",
    "        ).input_ids.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.__model(input_features=self.__audio_inputs, labels=target)\n",
    "\n",
    "        return outputs.loss.item()\n",
    "\n",
    "\n",
    "class Environment(object):\n",
    "    def __init__(self, init_state, cost_function, phoneme_table) -> None:\n",
    "        self.init_state = init_state\n",
    "        self.phoneme_table = deepcopy(phoneme_table)\n",
    "        self.__cost_function = cost_function\n",
    "\n",
    "    def compute_cost(self, text):\n",
    "        # try:\n",
    "        cost = self.__cost_function(text)\n",
    "        # except:\n",
    "        #     cost = 1e6\n",
    "        return cost\n",
    "replacement_lens = []\n",
    "matrix = {}\n",
    "for char in phenome_table:\n",
    "\tfor replacement in phenome_table[char]:\n",
    "\t\tif(replacement not in matrix):\n",
    "\t\t\tmatrix[replacement] = []\n",
    "\t\tmatrix[replacement].append(char)\n",
    "\n",
    "for rep in matrix:\n",
    "    if(len(rep) not in replacement_lens):\n",
    "        replacement_lens.append(len(rep))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = [\n",
    "    \"SHE FORMED AMONG THE FLICKERING SHADOWS A GRACEFUL AND HARMONIOUS IMAGE\",\n",
    "    \"AND WHO FROM A PRIVATE STATION HAD MOUNTED IN THE EARLIEST YOUTH\",\n",
    "    \"IAI CAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
    "    \"WHICH MOST FREQUENTLY CAN BE TRACED BACK TO THE UNBOUNDED EGOISM OF THE DREAMER\",\n",
    "    \"AND THAT FRESH HEARER WAS MARTIN POYSER WHO AS HIS WIFE SAID\",\n",
    "    \"HESITATION WHAT DO YOU KNOW ASKED OLD MOTHER NATURE HESITATION\",\n",
    "    \"MISTER FRANK CHURCHILL WAS ONE OF THE BOASTS OF HIGHBURY AND A LIVELY CURIOSITY TO SEE HIM PREVAILED\",\n",
    "    \"SO THAT THE WATERS WERE MADE TO STAND FIRM AS A WALL ON EITHER SIDE\",\n",
    "    \"THE MERCHANT BEING RECOVERED FROM HIS TERROR MOUNTED HIS HORSE AND PROCEEDED ON HIS JOURNEY\",\n",
    "    \"I DARESAY ONE WOULD BE ALLOWED TO SEE OVER THE HOUSE\",\n",
    "    \"TAKING A FINAL SPURT DOWN TO A FERRY LANDING A QUARTER OF A MILE BEYOND ON THE SOUTH BANK\",\n",
    "    \"ITALIANS ALL READY THEY ANSWERED AND THE LIEUTENANT LED THE WAY TO THE TRAIN\",\n",
    "    \"AND SHE CAME YET HALTING FROM HER RECENT WOUND TAKE HER SAYS PLUTO AND LEAD HER BACK TO THE LIGHT\",\n",
    "    \"WITH LOUD ACCLAMATIONS CRIED OUT VICTORY VICTORY IN FAVOUR OF THE CHAMPION IN WHITE\",\n",
    "    \"OH IT'S AT THE REHEARSALS YOU KNOW THAT THE FUN IS\",\n",
    "    \"DAUPHINES WITHOUT A RIGHT OR WRONG SIDE IN THE PIECE\",\n",
    "    \"NOT THAT I THINK CHARLOTTE SO VERY PLAIN BUT THEN SHE IS OUR PARTICULAR FRIEND\",\n",
    "    \"AND THEN COMES MURDER CREEK WHICH TAKES YOU ON TO TARRANGOWER\",\n",
    "    \"TURNING AWAY TOWARD THE GREEN MEADOWS INSTEAD PETER DIDN'T WAIT FOR SCRAPPER TO RETURN\",\n",
    "    \"HE LEFT SO AS TO SEEK AFTER BERNARD SAID LUCY QUICKLY MISTER DURHAM TOLD ME SO\",\n",
    "    \"THE TONES THE LOOKS THAT HAD ACCOMPANIED THOSE WORDS BUT ALL SHE SAID WAS I DIDN'T THINK TO SEE YO\",\n",
    "    \"AT THE SAME TIME AS THE MOUTH BETWEEN THE WHEELS A HEAD WAS PUT THROUGH THE WINDOW\",\n",
    "    \"THEY ARE A SMALLER HORDE THAN THE THARKS BUT MUCH MORE FEROCIOUS\",\n",
    "    \"WHICH IN THESE PEACEFUL TIMES IS FOR ME A SUFFICIENTLY PLEASING PICTURE OF WAR ON A SMALL SCALE\",\n",
    "    \"AND THEN TO BANISH US OUT OF SYRIA FOR EVER BUT HOW UNWORTHY SOEVER OUR USAGE HAS BEEN\",\n",
    "    \"THE THORN GROWS WITH THE ROSE THE POISON TREE AND THE CINNAMON MINGLE THEIR BOUGHS\",\n",
    "    \"HOW THE FATHER DOTED ON THE SMILES OF THE INFANT\",\n",
    "    \"ARE THE GOLDEN AGE AND DREAM DAYS AM I NOT RIGHT THANK YOU BUT THE BOOK YOU HAVE NOT READ MY BOOK\",\n",
    "    \"THE DURATION IN OFFICE OF THE EXECUTIVE FROM THE NEW YORK PACKET\",\n",
    "    \"IS THE CHILD OF YOUR THOUGHT\",\n",
    "    \"AND IF HE DOESN'T LISTEN TO MY ADVICE I AM GOING TO MAKE IT AS UNPLEASANT AS I CAN PRESIDENT WILSON\",\n",
    "    \"THERE WAS GOOD REASON TO STOP AND THINK EVEN FOR THE WORLD'S MOST EMOTIONLESS MAN\",\n",
    "    \"GLADLY WILL I DO SO ANSWERED PERCEVAL SO THEY WENT TOGETHER TO ARTHUR AND SALUTED HIM\",\n",
    "    \"ME THEY STRIPPED LIKE A SLAVE THEY LED ME THROUGH THE CITY AND THE PEOPLE MOCKED ME\",\n",
    "    \"AND EVEN MORE CONTEMPTIBLE THAN THAT IS MY MAKING THIS REMARK NOW BUT THAT'S ENOUGH\",\n",
    "    \"WORTHY FOSTER FATHER WELL WELL\",\n",
    "    \"THE THIRD MAN FROM THE END OH PATTY DID YOU BRING US SOME WEDDING CAKE DID YOU HAVE ANY ADVENTURES\",\n",
    "    \"SEVERAL PIPES THAT HAD BEEN EXTINGUISHED WERE LIGHTED AGAIN\",\n",
    "    \"TO A THIRD THE EAST TO A FOURTH THE WEST\",\n",
    "    \"THE OLD MAN HAD IN THE MEANTIME BEEN PENSIVE BUT ON THE APPEARANCE OF HIS COMPANIONS\",\n",
    "    \"THE YOUNG WOMAN WHEN SHE OPENED THE DOOR IN THE MORNING\",\n",
    "    \"AYE AND FOUND IT LIGHTER TOO SOME DAY FOR SURELY SURELY THIS IS NOT THE END\",\n",
    "    \"WHICH WILL PREVENT YOU FROM BEING BURNED UP AND CURE YOU IF YOU CHANCE TO BE A LITTLE SCORCHED\",\n",
    "    \"I WAS ENTIRELY WITHOUT FRIENDS NAY EVEN SO MUCH AS WITHOUT ACQUAINTANCE\",\n",
    "    \"HE MOVED A LITTLE AND SUDDENLY THERE WAS A RINGING IN HIS EARS\",\n",
    "    \"ONE WOULD DROP INTO THE BOAT WE SOON DISCOVERED SOME INDIANS FOLLOWING THE SCHOOL\",\n",
    "    \"OUTWARD FORMS AND SYMBOLS MUST BE USED TO CONVEY INTELLECTUAL CONCEPTIONS\",\n",
    "    \"TURNING TO HIS SECRETARY OF STATE HE SAID TO EXPLAIN HIS HESITATION\",\n",
    "    \"LAWYER WATSON AND UNCLE JOHN WERE THERE LOOKING AS GRAVE AS THE IMPORTANT OCCASION DEMANDED\",\n",
    "    \"SHALMANESER THE THIRD OF ASSYRIA FOUND IT NECESSARY TO INVADE BABYLONIA\",\n",
    "    \"TWENTIETH ROW SEAMED MAKE ONE AT THE BEGINNING TWENTY FIRST ROW SAME AS ELEVENTH\",\n",
    "    \"BEYOND THE SOUTHERN BOUNDARY OF THE TERRITORY GASHED BY STUPENDOUS CANYONS\",\n",
    "    \"WITHIN A FEW MINUTES THEIR RUNNING FOOTSTEPS HAD DIED AWAY IN THE DISTANCE\",\n",
    "    \"THEUNG SAID LET US BLESS HEAVEN FOR HAVING BROUGHT US ALL TOGETHER\",\n",
    "    \"RUSSEN AND FAIR PULLING LYON RILEY CHESHIRE AND LESLY WITH MUSKETS AND JOHN REX IN THE STERN SHEETS\",\n",
    "    \"LOOKED AWAY AS SOON AS POSSIBLE\",\n",
    "    \"MARIANNE LOOKED WITH AMAZEMENT AT EDWARD WITH COMPASSION AT HER SISTER\",\n",
    "    \"SURELY LUCK HAS BROUGHT US ALSO TO A NEW COUNTRY\",\n",
    "    \"INVINCIBLE JEALOUSY AND HATE INVOLUNTARY THRILL OF GRATIFIED VANITY INVOLVED IN PROFOUND UNCERTAINTY\",\n",
    "    \"OTHERS WISH HIM TO BE CHOSEN BY THE DECEASED OR ASSUMED BY THE LAW TO BE SO CHOSEN\",\n",
    "    \"STOCKINGS HAD TO BE DRAWN OFF VIOLENTLY BY ANOTHER PERSON\",\n",
    "    \"THOUGH THERE'S SOME ON IT AS ONE'S NO NEED TO SEE THE SMELL'S ENOUGH\",\n",
    "    \"SERVING AS A SAFE DEPOSITORY OF THE ARTICLES MENTIONED TO DANTES\",\n",
    "    \"CARBINEER IF THE SAME TO YOU MASTER SAID THE OTHER QUIETLY I NEVER SERVED IN THE INFANTRY\",\n",
    "    \"JACKSON WHAT TIME DID MISTER WOODS GET OUT HERE ON THE EVENING MISTER FELDERSON WAS KILLED\",\n",
    "    \"CHAMBERS WHICH ON ONE MELANCHOLY OCCASION DID BECOME ABSOLUTELY SUICIDAL\",\n",
    "    \"NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\",\n",
    "    \"SKELETONS THEY WERE AND NO HUMAN BEINGS AT ALL HER FATHER\",\n",
    "    \"EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\",\n",
    "    \"RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\",\n",
    "    \"TENAYA INQUIRED WHAT WAS THE OBJECT OF TAKING ALL THE INDIANS TO THE SAN JOAQUIN PLAIN MY PEOPLE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.83 GiB of which 3.00 MiB is free. Process 1599 has 55.55 MiB memory in use. Including non-PyTorch memory, this process has 1.76 GiB memory in use. Of the allocated memory 1.57 GiB is allocated by PyTorch, and 142.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m      7\u001b[0m avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m cost_model \u001b[38;5;241m=\u001b[39m \u001b[43mCostModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(data):\n\u001b[1;32m     10\u001b[0m         audio \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mCostModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Load Whisper model and processor\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__processor \u001b[38;5;241m=\u001b[39m WhisperProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/whisper-small.en\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__model \u001b[38;5;241m=\u001b[39m \u001b[43mWhisperForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai/whisper-small.en\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__audio_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2905\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2901\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2904\u001b[0m         )\n\u001b[0;32m-> 2905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.83 GiB of which 3.00 MiB is free. Process 1599 has 55.55 MiB memory in use. Including non-PyTorch memory, this process has 1.76 GiB memory in use. Of the allocated memory 1.57 GiB is allocated by PyTorch, and 142.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "audio = None\n",
    "sr = None\n",
    "text = None\n",
    "pred = None\n",
    "corrected_texts = []\n",
    "i = 0 \n",
    "avg = 0\n",
    "cost_model = CostModel()\n",
    "for sample in tqdm(data):\n",
    "        audio = sample['audio']['array']\n",
    "        sr = sample['audio']['sampling_rate']\n",
    "        text = sample['text']\n",
    "        cost_model.set_audio(audio, sr)\n",
    "        avg += cost_model(ans[i])\n",
    "        i+=1\n",
    "        # print(text)\n",
    "        # environment = Environment(text, cost_model.get_loss, phenome_table)\n",
    "\n",
    "        # # try:\n",
    "        # agent.asr_corrector(environment)\n",
    "        # pred = agent.best_state\n",
    "        # except:\n",
    "        #     pred = None\n",
    "        # corrected_texts.append(text)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 182.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 'HER', 3.668325424194336, 'HER', 3.668325424194336)\n",
      "(4, 'HER', 3.668325424194336, 'HER', 3.668325424194336)\n",
      "(4, 'HER', 3.668325424194336, 'HER', 3.668325424194336)\n",
      "(4, 'FADER', 3.668325424194336, 'FATHER', 3.424816846847534)\n",
      "(14, 'FADER', 3.668325424194336, 'FATHER', 3.424816846847534)\n",
      "(63, 'FADER', 3.668325424194336, 'FATHER', 3.424816846847534)\n",
      "(2, 'NOW', 3.424816846847534, 'NAUW', 3.1305131912231445)\n",
      "(4, 'NOW', 3.424816846847534, 'NAUR', 3.117487668991089)\n",
      "(12, 'NOW', 3.424816846847534, 'NAUR', 3.117487668991089)\n",
      "(11, 'NISTER', 3.117487668991089, 'MISTER', 2.6546361446380615)\n",
      "(20, 'NISTER', 3.117487668991089, 'MISTER', 2.6546361446380615)\n",
      "(51, 'NISTER', 3.117487668991089, 'MISTER', 2.6546361446380615)\n",
      "(13, 'ALLEN', 2.6546361446380615, 'ALLEN', 2.6546361446380615)\n",
      "(70, 'ALLEN', 2.6546361446380615, 'ALLEN', 2.6546361446380615)\n",
      "(70, 'ALLEN', 2.6546361446380615, 'ALLEN', 2.6546361446380615)\n",
      "(5, 'DID', 2.6546361446380615, 'DID', 2.6546361446380615)\n",
      "(14, 'DID', 2.6546361446380615, 'DID', 2.6546361446380615)\n",
      "(14, 'DID', 2.6546361446380615, 'DID', 2.6546361446380615)\n",
      "(3, 'SO', 2.6546361446380615, 'SO', 2.6546361446380615)\n",
      "(3, 'SO', 2.6546361446380615, 'SO', 2.6546361446380615)\n",
      "(3, 'SO', 2.6546361446380615, 'SO', 2.6546361446380615)\n",
      "(4, 'IT', 2.6546361446380615, 'IT', 2.6546361446380615)\n",
      "(4, 'IT', 2.6546361446380615, 'IT', 2.6546361446380615)\n",
      "(4, 'IT', 2.6546361446380615, 'IT', 2.6546361446380615)\n",
      "(6, 'WAS', 2.6546361446380615, 'WAS', 2.6546361446380615)\n",
      "(6, 'WAS', 2.6546361446380615, 'WAS', 2.6546361446380615)\n",
      "(6, 'WAS', 2.6546361446380615, 'WAS', 2.6546361446380615)\n",
      "(17, 'CERTAINLY', 2.6546361446380615, 'CERTAINLY', 2.6546361446380615)\n",
      "(36, 'CERTAINLY', 2.6546361446380615, 'CERTAINLY', 2.6546361446380615)\n",
      "(36, 'CERTAINLY', 2.6546361446380615, 'CERTAINLY', 2.6546361446380615)\n",
      "(4, 'VERY', 2.6546361446380615, 'VERY', 2.6546361446380615)\n",
      "(17, 'VERY', 2.6546361446380615, 'VERY', 2.6546361446380615)\n",
      "(17, 'VERY', 2.6546361446380615, 'VERY', 2.6546361446380615)\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "COUNTRY HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "CHARACTER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "MANNER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "PEOPLE HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "HESITATION HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "CARNIVAL HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "ITALIANS HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "FATHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVINCE\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY DISCUSSION\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY VARIOUS\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY HESITATION\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY KNOWLEDGE\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY SOCIETY\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY CHAMBERS\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOCATION\n",
      "NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "audio = None\n",
    "sr = None\n",
    "text = None\n",
    "pred = None\n",
    "corrected_texts = []\n",
    "cost_model = CostModel()\n",
    "total_cost = 0.0\n",
    "i = 0\n",
    "for sample in tqdm(data):\n",
    "        audio = sample['audio']['array']\n",
    "        sr = sample['audio']['sampling_rate']\n",
    "        text = sample['text']\n",
    "        cost_model.set_audio(audio, sr)\n",
    "        total_cost += compute_cost(ans[i])\n",
    "        i += 1\n",
    "        # print(text)\n",
    "        # environment = Environment(text, cost_model.get_loss, phenome_table)\n",
    "\n",
    "        # # try:\n",
    "        # agent.asr_corrector(environment)\n",
    "        # pred = agent.best_state\n",
    "        # except:\n",
    "        #     pred = None\n",
    "        corrected_texts.append(text)\n",
    "        # break\n",
    "cost_model.set_audio(audio,sr)\n",
    "environment = Environment(text, cost_model.get_loss, phenome_table)\n",
    "\n",
    "def cost(text):\n",
    "    return environment.compute_cost(text)\n",
    "\n",
    "# start_state = text\n",
    "# words = start_state.split()\n",
    "# beam = []\n",
    "# wbeams =[[word] for word in words ]\n",
    "# wpq =[PriorityQueue() for _ in words]\n",
    "# d = [{} for _ in words]\n",
    "# best_words = [None for _ in words]\n",
    "# def optimize_word(word,idx,epsilon,beam_size=30000,beam_depth=2,best_n=20):\n",
    "#     best_word  = word\n",
    "#     global current_state\n",
    "#     best_cost = cost(current_state)\n",
    "#     initial_word = word\n",
    "#     inital_cost = best_cost\n",
    "#     wpq[idx].put((best_cost,best_word))\n",
    "#     d[idx][best_word] = best_cost\n",
    "#     f = 1 +epsilon*len(best_word)\n",
    "#     count = 0\n",
    "#     for depth in range(beam_depth):\n",
    "#         stop = False\n",
    "#         queue = PriorityQueue()\n",
    "#         new_beam = []\n",
    "#         for current_word in wbeams[idx]:\n",
    "#             for l in replacement_lens:\n",
    "#                 for j in range(len(current_word)):\n",
    "#                     if(j+l>len(current_word)): continue\n",
    "#                     to_replace = current_word[j:j+l]\n",
    "#                     if to_replace in matrix:\n",
    "#                         for replacement in matrix[to_replace]:\n",
    "#                             new_word = current_word[:j]+replacement + current_word[j+l:]\n",
    "#                             words[idx] = new_word\n",
    "#                             new_sentence = ' '.join(words)\n",
    "#                             if(new_word not in d[idx]):\n",
    "#                                 c = cost(new_sentence)\n",
    "#                                 d[idx][new_word] = c\n",
    "#                                 queue.put((c,new_word))\n",
    "#                                 wpq[idx].put((c,new_word))\n",
    "#                                 if(c<best_cost):\n",
    "#                                     best_cost = c\n",
    "#                                     best_word = new_word\n",
    "#                                     count = 0\n",
    "#                                 else:\n",
    "#                                     count +=1\n",
    "#                                 if(count>=100):\n",
    "#                                     stop = True\n",
    "#                                 # print((c,new_sentence,best_word,len(wbeams[idx])))\n",
    "#         if(stop):\n",
    "#             break\n",
    "#         next_beam_size = 0\n",
    "#         while((next_beam_size<beam_size) and not queue.empty()):\n",
    "#             word_cost,beam_word, = queue.get()\n",
    "#             if(word_cost<f*best_cost):\n",
    "#                 new_beam.append(beam_word)\n",
    "#                 next_beam_size+=1\n",
    "#                 if(word_cost<best_cost):\n",
    "#                     best_cost = word_cost\n",
    "#                     best_word = beam_word\n",
    "#             else: break\n",
    "#         wbeams[idx] = new_beam\n",
    "#         print((count,initial_word,inital_cost,best_word,best_cost))\n",
    "#         if(count>=100 and initial_word == best_word):\n",
    "#             break\n",
    "\n",
    "#     ans = []\n",
    "#     a = wpq[idx].get()\n",
    "#     ans.append(a[1])\n",
    "#     u = []\n",
    "#     for _ in range(best_n):\n",
    "#         if not wpq[idx].empty():\n",
    "#             cw  = wpq[idx].get()\n",
    "#             if(a[0]*f> cw[0]):\n",
    "#                 ans.append(cw[1])\n",
    "#             else: break\n",
    "#         else: break\n",
    "#     best_words[idx] = ans\n",
    "#     words[idx] = ans[0]\n",
    "#     current_state = ' '.join(words)\n",
    "\n",
    "\n",
    "# current_state = start_state \n",
    "# for i,w in enumerate(start_state.split()):\n",
    "#     optimize_word(w,i,beam_size=300,beam_depth=3,epsilon=0.020,best_n=10)\n",
    "#     words[i] = best_words[i][0]\n",
    "# best_cost = cost(current_state)\n",
    "\n",
    "# prq = PriorityQueue()\n",
    "# beam_depth = 4\n",
    "# beam_size = 20\n",
    "\n",
    "# for _ in range(beam_depth):\n",
    "#     bs_words = current_state.split(' ')\n",
    "#     best_cost = cost(current_state)\n",
    "#     for i, word in enumerate(bs_words):\n",
    "#         replacement_words = best_words[i]\n",
    "#         current_word = word\n",
    "#         for word1 in replacement_words:\n",
    "#             bs_words[i] = word1\n",
    "#             sentence_potential = ' '.join(bs_words)\n",
    "#             cost_potential = cost(sentence_potential)\n",
    "#             prq.put((-1*cost_potential,sentence_potential))\n",
    "#             if(prq.qsize()>beam_size):\n",
    "#                 prq.get()\n",
    "#             if cost_potential<best_cost:\n",
    "#                 best_cost = cost_potential\n",
    "#                 current_state = sentence_potential\n",
    "#                 current_word = bs_words[i]\n",
    "#         bs_words[i] = current_word\n",
    "\n",
    "# k = 10\n",
    "# current_sentence = current_state\n",
    "# best_state = current_state\n",
    "# prq1 = PriorityQueue()\n",
    "# best_cost = cost(best_state)\n",
    "# for word in vocabulary:\n",
    "# \tnew_sentence = word + \" \" + current_sentence\n",
    "# \tnew_cost = cost(new_sentence)\n",
    "# \tif new_cost < best_cost:\n",
    "# \t\tbest_state = new_sentence\n",
    "# \t\tbest_cost = new_cost\n",
    "# \tprq1.put((-1*new_cost,word))\n",
    "# \tif prq1.qsize() >= k:\n",
    "# \t\tprq1.get()\n",
    "\n",
    "# prq2 = PriorityQueue()\n",
    "# for word in vocabulary:\n",
    "# \tnew_sentence = current_sentence  + \" \" + word\n",
    "# \tnew_cost = cost(new_sentence)\n",
    "# \tif new_cost < best_cost:\n",
    "# \t\tbest_state = new_sentence\n",
    "# \t\tbest_cost = new_cost\n",
    "# \tprq2.put((-1*new_cost,word))\n",
    "# \tif prq2.qsize() >= k:\n",
    "# \t\tprq2.get()\n",
    "\n",
    "# list1 = [prq1.get()[1] for _ in range(prq1.qsize())]\n",
    "# list2 = [prq2.get()[1] for _ in range(prq2.qsize())]\n",
    "\n",
    "# for elem1 in list1:\n",
    "# \tfor elem2 in list2:\n",
    "# \t\tnew_sentence = elem1 + \" \"+current_sentence + \" \"+elem2\n",
    "# \t\tprint(new_sentence)\n",
    "# \t\tnew_cost = cost(new_sentence)\n",
    "# \t\tif new_cost < best_cost:\n",
    "# \t\t\tbest_state = new_sentence\n",
    "# \t\t\tbest_cost = new_cost\n",
    "# final.append(best_state)\n",
    "# current_state\n",
    "# for 6,w in enumerate(words):\n",
    "#     for x in best_words[i]:\n",
    "#         words[i] = x\n",
    "#         new_sentence=  ' '.join(words)\n",
    "#         c = cost(new_sentence)\n",
    "#         if(c < best_cost):\n",
    "#             best_cost = c\n",
    "#             current_state = new_sentence\n",
    "#         else:\n",
    "#             words[i]  = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HER'],\n",
       " ['FATHER',\n",
       "  'FAITHER',\n",
       "  'FADER',\n",
       "  'FAUTHER',\n",
       "  'FATHHER',\n",
       "  'FATHIER',\n",
       "  'FAETHER',\n",
       "  'FATHHAER',\n",
       "  'FATHHAIR'],\n",
       " ['NAUR', 'NAUW', 'NAUUR', 'NOR'],\n",
       " ['MISTER', 'MISTEUR', 'MISTAIR', 'MISTAER'],\n",
       " ['ALLEN', 'ALLIEN', 'ALLEM', 'ARLEN', 'ALLAEN', 'ALLAIN'],\n",
       " ['DID', 'DIED'],\n",
       " ['SO'],\n",
       " ['IT'],\n",
       " ['WAS'],\n",
       " ['CERTAINLY', 'CEURTAINLY'],\n",
       " ['VERY', 'VEURY', 'VAIRY']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEITHER HER FATHER NOR MISTER ALLEN DID SO IT WAS CERTAINLY VERY PROVOKING'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.79040277004242"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.1194543838501"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [11, 15, 17, 20, 26, 29]\n",
    "data = [data[i] for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'audio': {'array': array([-1.61743164e-03, -1.37329102e-03, -9.76562500e-04, ...,\n",
       "          -9.15527344e-05, -3.05175781e-05, -1.52587891e-04]),\n",
       "   'sampling_rate': 16000},\n",
       "  'gold': 'ALL READY THEY ANSWERED AND THE LIEUTENANT LED THE WAY TO THE TRAIN',\n",
       "  'text': 'ALL READY THEY ANSWERED AND THE LIOTENANT LED FE WAY TO THE TLAIN'},\n",
       " {'audio': {'array': array([-0.00152588,  0.00259399,  0.00375366, ..., -0.00094604,\n",
       "          -0.00021362,  0.00079346]),\n",
       "   'sampling_rate': 16000},\n",
       "  'gold': 'DAUPHINES WITHOUT A RIGHT OR WRONG SIDE IN THE PIECE',\n",
       "  'text': 'DAUPHINES WITHOUT A RIGHT OR WRONG SIDE IN TE PIECE'},\n",
       " {'audio': {'array': array([-0.02770996, -0.02893066, -0.02896118, ..., -0.0050354 ,\n",
       "          -0.00552368, -0.00509644]),\n",
       "   'sampling_rate': 16000},\n",
       "  'gold': 'AND THEN COMES MURDER CREEK WHICH TAKES YOU ON TO TARRANGOWER',\n",
       "  'text': 'AND FEN COMEZ MURDEW CLEEK WHICH TAKES YOU ON TO TARRANGOWER'},\n",
       " {'audio': {'array': array([0.        , 0.        , 0.        , ..., 0.00088501, 0.00085449,\n",
       "          0.00085449]),\n",
       "   'sampling_rate': 16000},\n",
       "  'gold': \"THE TONES THE LOOKS THAT HAD ACCOMPANIED THOSE WORDS BUT ALL SHE SAID WAS I DIDN'T THINK TO SEE YO\",\n",
       "  'text': \"THE TONEZ THE LOOKS THAT HAD ACCOMPANAD THOSHE WORDZ BUT ALL SHE SHAID WASH I DIDN'T THINK TO SEE YO\"},\n",
       " {'audio': {'array': array([-0.00405884, -0.00241089,  0.00012207, ..., -0.00244141,\n",
       "          -0.0012207 , -0.00152588]),\n",
       "   'sampling_rate': 16000},\n",
       "  'gold': 'HOW THE FATHER DOTED ON THE SMILES OF THE INFANT',\n",
       "  'text': 'HOW THE FATHEW DOTED ON THE SNILES OF THE INFANT'},\n",
       " {'audio': {'array': array([ 0.00372314,  0.0020752 , -0.00222778, ..., -0.00036621,\n",
       "          -0.00042725, -0.00024414]),\n",
       "   'sampling_rate': 16000},\n",
       "  'gold': 'IS THE CHILD OF YOUR THOUGHT',\n",
       "  'text': 'IS DE CHILD OF YOUR THOUGHT'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "HESITATION WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "COUNTRY WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "CRACKED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "STANDING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "ATTACHED WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "CHANNEL WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "ITALIANS WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "CHATTERING WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CARNIVAL\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CONSCIOUSNESS\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF FATHER\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF KNOWLEDGE\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHANNEL\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAPTER\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF SUCCESS\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF CHAMBERS\n",
      "RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "current_sentence = current_state\n",
    "best_state = current_state\n",
    "prq1 = PriorityQueue()\n",
    "best_cost = cost(best_state)\n",
    "for word in vocabulary:\n",
    "\tnew_sentence = word + \" \" + current_sentence\n",
    "\tnew_cost = cost(new_sentence)\n",
    "\tif new_cost < best_cost:\n",
    "\t\tbest_state = new_sentence\n",
    "\t\tbest_cost = new_cost\n",
    "\tprq1.put((-1*new_cost,word))\n",
    "\tif prq1.qsize() >= k:\n",
    "\t\tprq1.get()\n",
    "\n",
    "prq2 = PriorityQueue()\n",
    "for word in vocabulary:\n",
    "\tnew_sentence = current_sentence  + \" \" + word\n",
    "\tnew_cost = cost(new_sentence)\n",
    "\tif new_cost < best_cost:\n",
    "\t\tbest_state = new_sentence\n",
    "\t\tbest_cost = new_cost\n",
    "\tprq2.put((-1*new_cost,word))\n",
    "\tif prq2.qsize() >= k:\n",
    "\t\tprq2.get()\n",
    "\n",
    "list1 = [prq1.get()[1] for _ in range(prq1.qsize())]\n",
    "list2 = [prq2.get()[1] for _ in range(prq2.qsize())]\n",
    "\n",
    "for elem1 in list1:\n",
    "\tfor elem2 in list2:\n",
    "\t\tnew_sentence = elem1 + \" \"+current_sentence + \" \"+elem2\n",
    "\t\tprint(new_sentence)\n",
    "\t\tnew_cost = cost(new_sentence)\n",
    "\t\tif new_cost < best_cost:\n",
    "\t\t\tbest_state = new_sentence\n",
    "\t\t\tbest_cost = new_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RETURN'D WITH A HEART OVERWHELM'D WITH DESPAIR TO THE COURT OF BABYLON\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "CHARACTER THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "CARNIVAL THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "CHOSEN THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "SNORING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "TURNING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "STANDING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "CHATTERING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "HESITATION THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS EXPOSING\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CONSISTENT\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS COUNTRY\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS SOCIETY\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHANNEL\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS KNOWLEDGE\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHAMBERS\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS CHARACTER\n",
      "EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EXPOSING THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS RESULT'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE CROWN ALTHOUGH THEIR CONCORD HAD ONLY EVIL AS ITS'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DAUPHINES WITHOUT A RIGHT OR WRONG SIDE IN THE PIECE'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALL READY THEY ANSWERED AND THE LIEUTENANT LED THE WAY TO THE TRAIN'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PriorityQueue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m words \u001b[38;5;241m=\u001b[39m current_state\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(beam_depth):\n\u001b[1;32m---> 10\u001b[0m \tprq \u001b[38;5;241m=\u001b[39m \u001b[43mPriorityQueue\u001b[49m()\n\u001b[0;32m     11\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m cs \u001b[38;5;129;01min\u001b[39;00m beam:\n\u001b[0;32m     12\u001b[0m \t\tcs_words \u001b[38;5;241m=\u001b[39m cs\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PriorityQueue' is not defined"
     ]
    }
   ],
   "source": [
    "beam_depth= 1\n",
    "beam_size = 20\n",
    "best_state = current_state\n",
    "beam = set()\n",
    "beam.add(current_state)\n",
    "vis = set()\n",
    "vis.add(current_state)\n",
    "words = current_state.split()\n",
    "for _ in range(beam_depth):\n",
    "\tprq = PriorityQueue()\n",
    "\tfor cs in beam:\n",
    "\t\tcs_words = cs.split(' ')\n",
    "\t\tfor i,word in enumerate(cs_words):\n",
    "\t\t\tfor pos_rep in best_words[i]:\n",
    "\t\t\t\tnew_sol = ' '.join(cs_words[:i]+[pos_rep]+cs_words[i+1:])\n",
    "\t\t\t\tif(new_sol in vis): continue\n",
    "\t\t\t\telse: vis.add(new_sol)\n",
    "\t\t\t\tc = cost(new_sol)\n",
    "\t\t\t\tprq.put((c, new_sol))\n",
    "\t\tnext_beam = set()\n",
    "\t\tfor _ in range(beam_size):\n",
    "\t\t\t\tpossol = prq.get()\n",
    "\t\t\t\tif(possol not in next_beam): next_beam.add(possol[1])\n",
    "\t\t\t\tif (possol[0] < cost(best_state)):\n",
    "\t\t\t\t\tbest_cost = possol[0]\n",
    "\t\t\t\t\tbest_state = possol[1]\n",
    "\t\t\t\t\tcurrent_state = best_state\n",
    "\t\tbeam = next_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"AE CAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"AI CAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"I CAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IAI CAEN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IAI CAIN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IAI CAN'T SAY WHETHER THERE IS A WILL OR KNOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IAI KAAEN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IAI KAEN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IAI KAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\",\n",
       " \"IE CAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I CAN'T SAY WHETHER THERE IS A WILL OR NOT LET US TALK OF SOMETHING ELSE\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
