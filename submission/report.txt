Anup Lal Nayak: 2022CS51827, Abhishek Amrendra Kumar: 2022CS11598

Approach and Optimizations in the Correction Agent for ASR Errors

1. Overview
The problem tackled involves correcting errors in text generated by Automatic Speech Recognition (ASR) systems.
These errors typically include incorrect character recognition and missing words at the start or end of a sentence.
The goal is to create an agent that refines the text to more closely match the intended spoken input using a search-based method, specifically local-search.

Local search was chosen over informed and uninformed search methods due to its suitability for handling large and complex search spaces like those encountered in ASR correction tasks.

Uninformed Search methods like Depth-First Search (DFS) and Breadth-First Search (BFS) are inefficient for this problem because they lack guidance and
would struggle with the exponential growth of possible corrections, especially in longer sentences.

Informed Search methods, such as A*, require a clear goal state and an effective heuristic, which can be difficult to define in this context since 
the goal is to minimize a cost function rather than reaching a predefined target state.

Local Search, in contrast, is well-suited for this task because it focuses on iteratively improving a single solution by exploring its neighboring states.
This approach efficiently navigates the search space to find low-cost corrections, making it more scalable and adaptable to the problem's complexity.


2. Core Approach
The agent is built around a beam search technique enhanced by local optimizations. The key steps include:

- Initialization: 
    The agent initializes by loading the phoneme table and vocabulary. This setup allows the agent to recognize possible substitutions for characters and potential missing words.
- Word-level Optimization: 
    Using the optimize_word function, the agent attempts to improve each word in the sentence individually.
    The process involves generating possible word substitutions based on the phoneme table, evaluating their cost, and retaining the best candidates in a list.
- Sentence-level Optimization: 
    The sentence_optimize function optimizes the entire sentence. Here, the beam search is applied to manage a set of candidate sentences,
     which are iteratively improved by substituting words with better alternatives identified during word-level optimization.
- Add-words:
    The agent identifies the top k prefix and suffix words based on their individual costs when added to the best sentence identified so far. 
    It then explores all combinations of these k prefixes and suffixes with the top n candidate sentences generated during the sentence optimization phase.
    The sentence with the lowest cost among these combinations is then selected as the best state.


3. Data Structures and Search Strategy
- Set + Priority Queues: 
    Implemented a data structure hybrid with the functionalities of a Set and a Priority Queue,
    (UniquePriorityQueue) are used extensively to manage and retrieve the best candidate words and sentences efficiently. 
    These priority queues ensure that the beam search remains focused on the most promising candidates while avoiding duplicates.
- Heuristic Function: 
    The heuristic in this context is the cost function provided by the environment, which evaluates the likelihood of a sentence matching the original audio. 
    Lower costs indicate better corrections.

4. Optimizations
- Beam Search Optimization: 
  - Adaptive Beam Length: 
    The beam length is dynamically adjusted based on the depth of the search and the progress made, which balances exploration and exploitation effectively.
  - Early Stopping: 
    The algorithm incorporates early stopping criteria, such as breaking out of the loop if the best word remains unchanged after a sufficient number of iterations.
- Word Prioritization: 
    In sentence optimization, more critical or promising words are prioritized based on their impact on the overall cost. This helps the search algorithm focus on impactful changes first.
- Multiple Beam Resolutions: 
    The agent utilizes different beam resolutions for word-level and sentence-level optimizations. The sentence-level beam search operates with a broader beam, while word-level optimizations use a more focused approach.

5. Complexity Considerations
- Branching Factor Control: By controlling the number of candidates in the beam and prioritizing based on cost, the algorithm manages the branching factor, 
    ensuring that the search remains computationally feasible even for longer sentences.
- Cost Function Independence: The implementation is agnostic of the specifics of the cost function, making it robust to different evaluation metrics that might be used during testing.

6. Conclusion
This agent leverages a combination of beam search, local optimization, and effective data management through priority queues to correct ASR errors efficiently. 
The design prioritizes flexibility, allowing it to adapt to different types of errors and sentence structures, while ensuring computational efficiency through various optimizations. 
This approach ensures that the agent can handle complex ASR errors within the time constraints, achieving higher accuracy in the corrected text.
